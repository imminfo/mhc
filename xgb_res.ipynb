{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run deps.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : loading Word2Vec object from ./trained_models/swissprot_reviewed_protvec\n",
      "INFO : setting ignored attribute syn0norm to None\n",
      "INFO : setting ignored attribute cum_table to None\n",
      "INFO : loaded ./trained_models/swissprot_reviewed_protvec\n"
     ]
    }
   ],
   "source": [
    "protvec_model = biovec.models.load_protvec('./trained_models/swissprot_reviewed_protvec')\n",
    "\n",
    "def seq2protvec(seq):\n",
    "    return sum(protvec_model.to_vecs(seq))\n",
    "\n",
    "def get_labels(labels_col):\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(labels_col)\n",
    "\n",
    "def get_protvec(data):\n",
    "    seq2pv = data.apply(seq2protvec)\n",
    "    seq2pv = list(seq2pv)\n",
    "    return seq2pv\n",
    "\n",
    "def meas2binary(meases):\n",
    "    return pd.Series(map(lambda x: 1 if x >= log_meas(500) else 0, meases))\n",
    "\n",
    "def xgb_regression(data, target):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=442)\n",
    "    \n",
    "    xgbr = xgb.XGBRegressor(max_depth=9, learning_rate=0.1, n_estimators=750, gamma=0, min_child_weight=5,\n",
    "                            reg_lambda = 0.3, subsample=0.9, colsample_bytree = 0.9, nthread=15, silent=False)\n",
    "    \n",
    "    xgbr.fit(X_train, y_train)\n",
    "    \n",
    "    preds = xgbr.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    f1 = f1_score(meas2binary(y_test), meas2binary(preds))\n",
    "    print(\"RMSE on test: {0:.4f}\".format(mse))\n",
    "    print(\"F1-score on test:{}\".format(f1))\n",
    "    return mse, f1\n",
    "\n",
    "def get_rmse_of_models(performance, my_performance_mse, my_performance_f1, alleles):\n",
    "    \n",
    "    \"\"\"\n",
    "    arguments:\n",
    "    \n",
    "    performance - \n",
    "    alleles - list of alleles names\n",
    "    my_performnace - \n",
    "    \n",
    "    --------\n",
    "    function get_rmse_of_models extract dataset of specific allele from performance dataset, calculates rmse on \n",
    "    each allele and stores it in dicts\n",
    "    --------\n",
    "    returns: 3 tuples\n",
    "    \n",
    "    netmhc_rmse - tuple of rmse of netmhc on every alelle\n",
    "    netmhcpan_rmse - tuple of rmse of netmhcpan on every alelle\n",
    "    pmbec_rmse - tuple of rmse of smm_pmbec on every alelle\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    netmhc_rmse = {}\n",
    "    netmhcpan_rmse = {}\n",
    "    pmbec_rmse = {}\n",
    "    mhc_rmse = {}\n",
    "    \n",
    "    netmhc_f1 = {}\n",
    "    netmhcpan_f1 = {}\n",
    "    pmbec_f1 = {}\n",
    "    mhc_f1 = {}\n",
    "    \n",
    "    for index, cur_al in enumerate(alleles):\n",
    "        \n",
    "        cur_alelle = select_by_allele(performance, cur_al)\n",
    "        print(\"\\n#{:d} {}:\".format(index, cur_al))\n",
    "        print(\"Shapes: \", cur_alelle.shape, cur_alelle.meas.shape)\n",
    "        if(len(cur_alelle) == 0):\n",
    "            continue\n",
    "        netmhc_rmse[cur_al] = mean_squared_error(cur_alelle.meas, cur_alelle.netmhc)\n",
    "        netmhcpan_rmse[cur_al] = mean_squared_error(cur_alelle.meas, cur_alelle.netmhcpan)\n",
    "        pmbec_rmse[cur_al] = mean_squared_error(cur_alelle.meas, cur_alelle.smmpmbec_cpp)\n",
    "        \n",
    "        netmhc_f1[cur_al] = f1_score(meas2binary(cur_alelle.meas), meas2binary(cur_alelle.netmhc))\n",
    "        netmhcpan_f1[cur_al] = f1_score(meas2binary(cur_alelle.meas), meas2binary(cur_alelle.netmhcpan))\n",
    "        pmbec_f1[cur_al] = f1_score(meas2binary(cur_alelle.meas), meas2binary(cur_alelle.smmpmbec_cpp))\n",
    "        \n",
    "    \n",
    "    netmhc_df = pd.DataFrame.from_dict(netmhc_rmse, orient='index')\n",
    "    netmhcpan_df = pd.DataFrame.from_dict(netmhcpan_rmse, orient='index')\n",
    "    pmbec_df = pd.DataFrame.from_dict(pmbec_rmse, orient='index')\n",
    "    xgb_df = pd.DataFrame.from_dict(my_performance_mse, orient='index')\n",
    "\n",
    "    models_perf_mse = pd.concat([xgb_df, netmhc_df, netmhcpan_df, pmbec_df], axis=1)\n",
    "    models_perf_mse.columns=[\"mhystic\", \"netmhc\", \"netmhcpan\", \"pmbec\"]\n",
    "    \n",
    "    netmhc_df = pd.DataFrame.from_dict(netmhc_f1, orient='index')\n",
    "    netmhcpan_df = pd.DataFrame.from_dict(netmhcpan_rmse, orient='index')\n",
    "    pmbec_df = pd.DataFrame.from_dict(pmbec_f1, orient='index')\n",
    "    xgb_df = pd.DataFrame.from_dict(my_performance_f1, orient='index')\n",
    "\n",
    "    models_perf_f1 = pd.concat([xgb_df, netmhc_df, netmhcpan_df, pmbec_df], axis=1)\n",
    "    models_perf_f1.columns=[\"mhystic\", \"netmhc\", \"netmhcpan\", \"pmbec\"]\n",
    "    \n",
    "    return models_perf_mse, models_perf_f1\n",
    "\n",
    "\n",
    "def evaluate_pv_by_allele(dataset, alleles):\n",
    "    \n",
    "    \"\"\"\n",
    "    arguments:\n",
    "    \n",
    "    alleles - list of alleles names\n",
    "    --------\n",
    "    function evaluate_by_allele extract dataset of specific allele from Bdata in which there are sequence and affinity \n",
    "    using select_by_allele function, saves it in csv, then constructing word2vec representation of this \n",
    "    sequences and evaluates xgb model, which return rmse on this allele.\n",
    "    --------\n",
    "    returns: \n",
    "    \n",
    "    mhc_rmse tuple of rmse on every allele in alleles\n",
    "    \"\"\"\n",
    "    \n",
    "    mhc_rmse = {}\n",
    "    mhc_f1 = {}\n",
    "    \n",
    "    for index,cur_al in enumerate(alleles):\n",
    "        \n",
    "        current_allele = select_by_allele(dataset, cur_al)\n",
    "        \n",
    "        if(len(current_allele) == 1):\n",
    "            continue\n",
    "            \n",
    "        cur_al_affinity = current_allele.meas\n",
    "        \n",
    "        #pv_protein = get_protvec(current_allele.protein)\n",
    "        pv_peptide = get_protvec(current_allele.sequence)\n",
    "        \n",
    "        #pv_mean = np.array([i/2 for i in np.add(pv_protein, pv_peptide)])\n",
    "        #pv_res = np.subtract(pv_protein, pv_peptide)\n",
    "        #pv_sum = np.add(pv_protein, pv_peptide)\n",
    "        \n",
    "        \n",
    "        print(\"\\n#{:d} {}:\".format(index, cur_al))\n",
    "        print(\"Shapes: \", current_allele.shape, cur_al_affinity.shape)\n",
    "        \n",
    "        allele_rmse, allele_f1 = xgb_regression(pv_peptide, cur_al_affinity)\n",
    "        mhc_rmse[cur_al] = allele_rmse\n",
    "        mhc_f1[cur_al] = allele_f1\n",
    "    \n",
    "    return mhc_rmse, mhc_f1\n",
    "\n",
    "def plot_results(results, description):\n",
    "    \n",
    "    \"\"\"\n",
    "    results - DataFrame with columns \"mhystic\", \"netmhc\", \"netmhcpan\", \"pmbec\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    allele_rmse_figure = plt.figure(figsize=(48, 27))\n",
    "    plt.title(\"RMSE.{}\".format(description))\n",
    "    plt.xlabel(\"$RMSE$\")\n",
    "    plt.ylabel(\"Alleles\")\n",
    "\n",
    "    ind = np.arange(0, 4*len(list(results.index)), 4) \n",
    "    width = 0.6\n",
    "    ys = plt.yticks(ind, list(results.index), rotation=0)\n",
    "    plt.locator_params(nbins=len(results.mhystic))\n",
    "\n",
    "    xgb_rects = plt.barh(ind, list(results.mhystic), width, align='center', color='red', alpha=0.3, label = 'MHystic', edgecolor='w')\n",
    "    plt.barh(ind + width , list(results.netmhc), width, align='center', color='yellow', alpha=0.3, label='netmhc')\n",
    "    plt.barh(ind + 2*width, list(results.netmhcpan), width, align='center', color='blue', alpha=0.3, label='netmhcpan')\n",
    "    plt.barh(ind + 3*width, list(results.pmbec), width, align='center', color='black', alpha=0.3, label='pmbec')\n",
    "\n",
    "    plt.legend(fontsize='xx-large')\n",
    "\n",
    "\n",
    "    rounded_rmse_xgb = [\"{0:.5f}\".format(i) for i in list(results.mhystic)]\n",
    "\n",
    "    for cur_rect, value in zip(xgb_rects.patches, rounded_rmse_xgb):\n",
    "        plt.text(cur_rect.get_width() +0.001, cur_rect.get_y() - 0.5, value, ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "    \n",
    "    allele_rmse_figure.savefig('rmse {}.png'.format(description), dpi=allele_rmse_figure.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Bdata = pd.read_csv(\"./data/bdata.csv\")\n",
    "Bdata.meas = [log_meas(i) for i in Bdata.meas]\n",
    "data9mers = Bdata[Bdata.peptide_length == 9].reset_index()\n",
    "\n",
    "hla_abce = select_hla(data9mers)\n",
    "seq_dict = pd.read_csv(\"./data/mhc_seq_imghtla.csv\")\n",
    "common = set(seq_dict.mhc).intersection(set(hla_abce.mhc))\n",
    "seq_dict = seq_dict[seq_dict[\"mhc\"].isin(common)].reset_index(drop=True)\n",
    "hla_abce = hla_abce.iloc[np.array(np.where(hla_abce.mhc.apply(lambda x:x in common))).flatten()].reset_index(drop=True)\n",
    "hla_abce[\"protein\"] = [seq_dict.loc[seq_dict.mhc==i].sequence.values[0] for i in hla_abce.mhc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proteins2pv = get_protvec(hla_abce.protein)\n",
    "peptides2pv = get_protvec(hla_abce.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pv_res = np.subtract(proteins2pv, peptides2pv)\n",
    "pv_div = np.divide(proteins2pv, peptides2pv)\n",
    "pv_sum = np.add(proteins2pv, peptides2pv)\n",
    "pv_mean = np.array([i/2 for i in pv_sum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#0 HLAA2301:\n",
      "Shapes:  (1784, 8) (1784,)\n",
      "RMSE on test: 0.0670\n",
      "F1-score on test:0.15151515151515152\n",
      "\n",
      "#1 HLAB2705:\n",
      "Shapes:  (2587, 8) (2587,)\n",
      "RMSE on test: 0.0412\n",
      "F1-score on test:0.18867924528301885\n",
      "\n",
      "#2 HLAA0101:\n",
      "Shapes:  (3680, 8) (3680,)\n",
      "RMSE on test: 0.0503\n",
      "F1-score on test:0.056338028169014086\n",
      "\n",
      "#3 HLAB0801:\n",
      "Shapes:  (2817, 8) (2817,)\n",
      "RMSE on test: 0.0641\n",
      "F1-score on test:0.33628318584070793\n",
      "\n",
      "#4 HLAB5101:\n",
      "Shapes:  (2031, 8) (2031,)\n",
      "RMSE on test: 0.0351\n",
      "F1-score on test:0.07547169811320754\n",
      "\n",
      "#5 HLAB5801:\n",
      "Shapes:  (2757, 8) (2757,)\n",
      "RMSE on test: 0.0583\n",
      "F1-score on test:0.2372881355932203\n",
      "\n",
      "#6 HLAA0203:\n",
      "Shapes:  (4427, 8) (4427,)\n",
      "RMSE on test: 0.0944\n",
      "F1-score on test:0.49002849002849\n",
      "\n",
      "#7 HLAB4002:\n",
      "Shapes:  (572, 8) (572,)\n",
      "RMSE on test: 0.0979\n",
      "F1-score on test:0.06779661016949153\n",
      "\n",
      "#8 HLAB0803:\n",
      "Shapes:  (451, 8) (451,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 0.0144\n",
      "F1-score on test:0.0\n",
      "\n",
      "#9 HLAA3001:\n",
      "Shapes:  (2426, 8) (2426,)\n",
      "RMSE on test: 0.0920\n",
      "F1-score on test:0.2453531598513011\n",
      "\n",
      "#10 HLAB1517:\n",
      "Shapes:  (1430, 8) (1430,)\n",
      "RMSE on test: 0.1074\n",
      "F1-score on test:0.19858156028368795\n",
      "\n",
      "#11 HLAA0206:\n",
      "Shapes:  (3732, 8) (3732,)\n",
      "RMSE on test: 0.0978\n",
      "F1-score on test:0.5378590078328982\n",
      "\n",
      "#12 HLAA0201:\n",
      "Shapes:  (8826, 8) (8826,)\n",
      "RMSE on test: 0.0878\n",
      "F1-score on test:0.47283406754772395\n",
      "\n",
      "#13 HLAA3002:\n",
      "Shapes:  (1202, 8) (1202,)\n",
      "RMSE on test: 0.0752\n",
      "F1-score on test:0.20512820512820512\n",
      "\n",
      "#14 HLAA0202:\n",
      "Shapes:  (2465, 8) (2465,)\n",
      "RMSE on test: 0.0937\n",
      "F1-score on test:0.5979020979020979\n",
      "\n",
      "#15 HLAB0802:\n",
      "Shapes:  (998, 8) (998,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 0.0090\n",
      "F1-score on test:0.0\n",
      "\n",
      "#16 HLAB3801:\n",
      "Shapes:  (491, 8) (491,)\n",
      "RMSE on test: 0.0455\n",
      "F1-score on test:0.7088607594936709\n",
      "\n",
      "#17 HLAB4601:\n",
      "Shapes:  (1784, 8) (1784,)\n",
      "RMSE on test: 0.0147\n",
      "F1-score on test:0.1739130434782609\n",
      "\n",
      "#18 HLAA3301:\n",
      "Shapes:  (1929, 8) (1929,)\n",
      "RMSE on test: 0.0622\n",
      "F1-score on test:0.19469026548672566\n",
      "\n",
      "#19 HLAB5301:\n",
      "Shapes:  (937, 8) (937,)\n",
      "RMSE on test: 0.0737\n",
      "F1-score on test:0.5\n",
      "\n",
      "#20 HLAA6801:\n",
      "Shapes:  (2036, 8) (2036,)\n",
      "RMSE on test: 0.0880\n",
      "F1-score on test:0.4054794520547945\n",
      "\n",
      "#21 HLAB1501:\n",
      "Shapes:  (3797, 8) (3797,)\n",
      "RMSE on test: 0.0686\n",
      "F1-score on test:0.2040816326530612\n",
      "\n",
      "#22 HLAA6802:\n",
      "Shapes:  (3672, 8) (3672,)\n",
      "RMSE on test: 0.0649\n",
      "F1-score on test:0.24305555555555555\n",
      "\n",
      "#23 HLAB1801:\n",
      "Shapes:  (2190, 8) (2190,)\n",
      "RMSE on test: 0.0390\n",
      "F1-score on test:0.03333333333333333\n",
      "\n",
      "#24 HLAB0702:\n",
      "Shapes:  (3619, 8) (3619,)\n",
      "RMSE on test: 0.0610\n",
      "F1-score on test:0.4509283819628648\n",
      "\n",
      "#25 HLAA2603:\n",
      "Shapes:  (517, 8) (517,)\n",
      "RMSE on test: 0.0412\n",
      "F1-score on test:0.0\n",
      "\n",
      "#26 HLAB3901:\n",
      "Shapes:  (1525, 8) (1525,)\n",
      "RMSE on test: 0.0382\n",
      "F1-score on test:0.07272727272727272\n",
      "\n",
      "#27 HLAA2601:\n",
      "Shapes:  (3559, 8) (3559,)\n",
      "RMSE on test: 0.0438\n",
      "F1-score on test:0.0\n",
      "\n",
      "#28 HLAB4403:\n",
      "Shapes:  (731, 8) (731,)\n",
      "RMSE on test: 0.0566\n",
      "F1-score on test:0.29090909090909095\n",
      "\n",
      "#29 HLAB4501:\n",
      "Shapes:  (574, 8) (574,)\n",
      "RMSE on test: 0.0550\n",
      "F1-score on test:0.0\n",
      "\n",
      "#30 HLAB5401:\n",
      "Shapes:  (721, 8) (721,)\n",
      "RMSE on test: 0.0752\n",
      "F1-score on test:0.20408163265306123\n",
      "\n",
      "#31 HLAA8001:\n",
      "Shapes:  (1162, 8) (1162,)\n",
      "RMSE on test: 0.0548\n",
      "F1-score on test:0.08333333333333333\n",
      "\n",
      "#32 HLAA1101:\n",
      "Shapes:  (4411, 8) (4411,)\n",
      "RMSE on test: 0.0768\n",
      "F1-score on test:0.2663934426229508\n",
      "\n",
      "#33 HLAB4001:\n",
      "Shapes:  (2609, 8) (2609,)\n",
      "RMSE on test: 0.0462\n",
      "F1-score on test:0.17821782178217824\n",
      "\n",
      "#34 HLAB5701:\n",
      "Shapes:  (2404, 8) (2404,)\n",
      "RMSE on test: 0.0477\n",
      "F1-score on test:0.12389380530973451\n",
      "\n",
      "#35 HLAA0301:\n",
      "Shapes:  (5231, 8) (5231,)\n",
      "RMSE on test: 0.0620\n",
      "F1-score on test:0.18407960199004972\n",
      "\n",
      "#36 HLAA2402:\n",
      "Shapes:  (2360, 8) (2360,)\n",
      "RMSE on test: 0.0619\n",
      "F1-score on test:0.2368421052631579\n",
      "\n",
      "#37 HLAB4402:\n",
      "Shapes:  (1571, 8) (1571,)\n",
      "RMSE on test: 0.0416\n",
      "F1-score on test:0.07407407407407407\n",
      "\n",
      "#38 HLAA2501:\n",
      "Shapes:  (935, 8) (935,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 0.0281\n",
      "F1-score on test:0.0\n",
      "\n",
      "#39 HLAA6901:\n",
      "Shapes:  (2557, 8) (2557,)\n"
     ]
    }
   ],
   "source": [
    "performance_data = pd.read_csv(\"./data/model_performance_logged.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "performance_data.tail()\n",
    "\n",
    "unify_alleles = lambda x: re.sub('[-|*]', '', x)\n",
    "\n",
    "performance_data.mhc = performance_data.mhc.apply(unify_alleles)\n",
    "\n",
    "common_alleles = list(set(hla_abce.mhc).intersection(performance_data.mhc))\n",
    "\n",
    "errors = evaluate_pv_by_allele(hla_abce, common_alleles)\n",
    "errors_rmse = OrderedDict(sorted(errors[0].items(), key=lambda t: t[0]))\n",
    "errors_f1 = OrderedDict(sorted(errors[1].items(), key=lambda t: t[0]))\n",
    "performance_df_mse, performance_df_f1 = get_rmse_of_models(performance_data, errors[0], errors[1], common_alleles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results(performance_df_mse.sort('mhystic', ascending=True), \"RMSE, pv, peptide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results(performance_df_f1.sort('mhystic', ascending=True), \"F1, pv, peptide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
